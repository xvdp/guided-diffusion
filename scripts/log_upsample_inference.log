Upsampming model trace input [2,64,64,3] -> [2,256,256,3]
{'attention_resolutions': '32,16,8',
 'base_samples': '/home/z/work/gits/Diffusion/guided-diffusion/results/upscale64/upsample_hare_downscale_.npz',
 'batch_size': 2,
 'class_cond': True,
 'clip_denoised': True,
 'diffusion_steps': 1000,
 'dropout': 0.0,
 'large_size': 256,
 'learn_sigma': True,
 'model_path': '../models/64_256_upsampler.pt',
 'noise_schedule': 'linear',
 'num_channels': 192,
 'num_head_channels': -1,
 'num_heads': 4,
 'num_heads_upsample': -1,
 'num_res_blocks': 2,
 'num_samples': 2,
 'predict_xstart': False,
 'resblock_updown': True,
 'rescale_learned_sigmas': False,
 'rescale_timesteps': False,
 'small_size': 64,
 'timestep_respacing': '250',
 'use_checkpoint': False,
 'use_ddim': False,
 'use_fp16': True,
 'use_kl': False,
 'use_scale_shift_norm': True}
Logging to /tmp/openai-2022-03-16-18-03-02-123951
creating model...
{'attention_resolutions': '32,16,8',
 'class_cond': True,
 'diffusion_steps': 1000,
 'dropout': 0.0,
 'large_size': 256,
 'learn_sigma': True,
 'noise_schedule': 'linear',
 'num_channels': 192,
 'num_head_channels': -1,
 'num_heads': 4,
 'num_heads_upsample': -1,
 'num_res_blocks': 2,
 'predict_xstart': False,
 'resblock_updown': True,
 'rescale_learned_sigmas': False,
 'rescale_timesteps': False,
 'small_size': 64,
 'timestep_respacing': '250',
 'use_checkpoint': False,
 'use_fp16': True,
 'use_kl': False,
 'use_scale_shift_norm': True}
SuperResModel.__init__():
Unet.__init__():
	in_channels 6
	out_channels 6
	model_channels 192
	num_res_blocks 2
	attention_resolutions (8, 16, 32)
	dropout 0.0
	conv_resample True
	num_classes 1000
	num_heads 4
	num_head_channels -1
	num_heads_upsample 4
	level[0], mult[1], res_block[0] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	level[0], mult[1], res_block[0] +TimestepEmbedSequential(*layers 1
	level[0], mult[1], res_block[1] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	level[0], mult[1], res_block[1] +TimestepEmbedSequential(*layers 1
	level[0], mult[1], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 192, time_embed_dim 768, dropout 0.0, out_channels 192, dims: 2
	 level[1], mult[1], res_block[0] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	 level[1], mult[1], res_block[0] +TimestepEmbedSequential(*layers 1
	 level[1], mult[1], res_block[1] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	 level[1], mult[1], res_block[1] +TimestepEmbedSequential(*layers 1
	 level[1], mult[1], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 192, time_embed_dim 768, dropout 0.0, out_channels 192, dims: 2
	  level[2], mult[2], res_block[0] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	  level[2], mult[2], res_block[0] +TimestepEmbedSequential(*layers 1
	  level[2], mult[2], res_block[1] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	  level[2], mult[2], res_block[1] +TimestepEmbedSequential(*layers 1
	  level[2], mult[2], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 384, time_embed_dim 768, dropout 0.0, out_channels 384, dims: 2
	   level[3], mult[2], res_block[0] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	   level[3], mult[2] ds 8 in attention_resolutions(8, 16, 32)] +AttentionBlock(ch384, num_heads:4, num_head_channels:-1), use_new_attention_order:False
	   level[3], mult[2], res_block[0] +TimestepEmbedSequential(*layers 2
	   level[3], mult[2], res_block[1] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	   level[3], mult[2] ds 8 in attention_resolutions(8, 16, 32)] +AttentionBlock(ch384, num_heads:4, num_head_channels:-1), use_new_attention_order:False
	   level[3], mult[2], res_block[1] +TimestepEmbedSequential(*layers 2
	   level[3], mult[2], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 384, time_embed_dim 768, dropout 0.0, out_channels 384, dims: 2
	    level[4], mult[4], res_block[0] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	    level[4], mult[4] ds 16 in attention_resolutions(8, 16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1), use_new_attention_order:False
	    level[4], mult[4], res_block[0] +TimestepEmbedSequential(*layers 2
	    level[4], mult[4], res_block[1] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	    level[4], mult[4] ds 16 in attention_resolutions(8, 16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1), use_new_attention_order:False
	    level[4], mult[4], res_block[1] +TimestepEmbedSequential(*layers 2
	    level[4], mult[4], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 768, time_embed_dim 768, dropout 0.0, out_channels 768, dims: 2
	     level[5], mult[4], res_block[0] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	     level[5], mult[4] ds 32 in attention_resolutions(8, 16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1), use_new_attention_order:False
	     level[5], mult[4], res_block[0] +TimestepEmbedSequential(*layers 2
	     level[5], mult[4], res_block[1] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	     level[5], mult[4] ds 32 in attention_resolutions(8, 16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1), use_new_attention_order:False
	     level[5], mult[4], res_block[1] +TimestepEmbedSequential(*layers 2
	      MiddleBlock: +TimestepEmbedSequential(ResBlock (ch: 768, time_embed_dim 768, dropout 0.0, out_channels 768, dims: 2
	      AttentionBlock (ch: 768, num_heads 4, num_head_channels -1, use_new_attention_order False
	      ResBlock (ch: 768, time_embed_dim 768, dropout 0.0, out_channels 768, dims: 2
	self._feature_size += ch  8256
	     level[5], mult[4], res_block[0] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	     level[5], mult[4], AttentionBlock[0: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1)
	     level[5], mult[4], res_block[1] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	     level[5], mult[4], AttentionBlock[1: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1)
	     level[5], mult[4], res_block[2] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	     level[5], mult[4], AttentionBlock[2: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1)
	     level[5], mult[4], res_block[2, level and i == num_res_blocks] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	    level[4], mult[4], res_block[0] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	    level[4], mult[4], AttentionBlock[0: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1)
	    level[4], mult[4], res_block[1] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	    level[4], mult[4], AttentionBlock[1: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1)
	    level[4], mult[4], res_block[2] +ResBlock(ch768 +ich384, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	    level[4], mult[4], AttentionBlock[2: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:-1)
	    level[4], mult[4], res_block[2, level and i == num_res_blocks] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	   level[3], mult[2], res_block[0] +ResBlock(ch768 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	   level[3], mult[2], AttentionBlock[0: ds in attention_resolutions] +AttentionBlock(ch384, num_heads:4, num_head_channels:-1)
	   level[3], mult[2], res_block[1] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	   level[3], mult[2], AttentionBlock[1: ds in attention_resolutions] +AttentionBlock(ch384, num_heads:4, num_head_channels:-1)
	   level[3], mult[2], res_block[2] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	   level[3], mult[2], AttentionBlock[2: ds in attention_resolutions] +AttentionBlock(ch384, num_heads:4, num_head_channels:-1)
	   level[3], mult[2], res_block[2, level and i == num_res_blocks] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	  level[2], mult[2], res_block[0] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	  level[2], mult[2], res_block[1] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	  level[2], mult[2], res_block[2] +ResBlock(ch384 +ich192, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	  level[2], mult[2], res_block[2, level and i == num_res_blocks] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	 level[1], mult[1], res_block[0] +ResBlock(ch384 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	 level[1], mult[1], res_block[1] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	 level[1], mult[1], res_block[2] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	 level[1], mult[1], res_block[2, level and i == num_res_blocks] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	level[0], mult[1], res_block[0] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	level[0], mult[1], res_block[1] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	level[0], mult[1], res_block[2] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
GaussianDiffusion.__init__()
  model_mean_type ModelMeanType.EPSILON
  model_var_type ModelVarType.LEARNED_RANGE
  loss_type LossType.MSE
  rescale_timesteps False
GaussianDiffusion.__init__()
  model_mean_type ModelMeanType.EPSILON
  model_var_type ModelVarType.LEARNED_RANGE
  loss_type LossType.MSE
  rescale_timesteps False
loading data...
creating samples...

GaussianDiffusion.p_sample_loop_progressive(indices: 250)
# p_sample feeds 1. output of last iteration, 2. timesteps, 3. conditional input
PRE.GaussianDiffusion.p_sample(x: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.48:4.61], cond_fn: None,
							   t: tensor([249, 249], device='cuda:0'),
							   model: SuperResModel
							   model_kwargs: {low_res:(2, 3, 64, 64)[∇:False μ:-0.37 σ:0.30 R:[-1.00:0.65],y:(2,)[∇:False],}
PRE.GaussianDiffusion.p_mean_variance(x: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.48:4.61],
									  kwargs:{low_res:(2, 3, 64, 64)[∇:False μ:-0.37 σ:0.30 R:[-1.00:0.65],y:(2,)[∇:False],}

SuperResModel.forward(x: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.48:4.61]
					  low_res: (2, 3, 64, 64)[∇:False μ:-0.37 σ:0.30 R:[-1.00:0.65],
					  t: [999, 999])
# SuperResModel concatenates into channels dimension(last_x, contitional)
SuperResModel.forward; x = cat(x, upsampled): (2, 6, 256, 256)[∇:False μ:-0.18 σ:0.76 R:[-4.48:4.61])
Unet.forward(x: (2, 6, 256, 256)[∇:False μ:-0.18 σ:0.76 R:[-4.48:4.61], t: torch.Size([2]), y: torch.Size([2]))

# Unets creates position embedding of timestep of size: (channels*heads)
Unet.forward(emb: torch.Size([2, 768]), timestep_embedding: torch.Size([2]), channels: 192)

Unet.forward: input.blocks(h: torch.Size([2, 6, 256, 256]), emb torch.Size([2, 768]) -> residual(0)
 Unet.forward: input.blocks(h: torch.Size([2, 192, 256, 256]), emb torch.Size([2, 768]) -> residual(1)
  Unet.forward: input.blocks(h: torch.Size([2, 192, 256, 256]), emb torch.Size([2, 768]) -> residual(2)
   Unet.forward: input.blocks(h: torch.Size([2, 192, 256, 256]), emb torch.Size([2, 768]) -> residual(3)
    Unet.forward: input.blocks(h: torch.Size([2, 192, 128, 128]), emb torch.Size([2, 768]) -> residual(4)
     Unet.forward: input.blocks(h: torch.Size([2, 192, 128, 128]), emb torch.Size([2, 768]) -> residual(5)
      Unet.forward: input.blocks(h: torch.Size([2, 192, 128, 128]), emb torch.Size([2, 768]) -> residual(6)
       Unet.forward: input.blocks(h: torch.Size([2, 192, 64, 64]), emb torch.Size([2, 768]) -> residual(7)
        Unet.forward: input.blocks(h: torch.Size([2, 384, 64, 64]), emb torch.Size([2, 768]) -> residual(8)
         Unet.forward: input.blocks(h: torch.Size([2, 384, 64, 64]), emb torch.Size([2, 768]) -> residual(9)
          Unet.forward: input.blocks(h: torch.Size([2, 384, 32, 32]), emb torch.Size([2, 768]) -> residual(10)
           Unet.forward: input.blocks(h: torch.Size([2, 384, 32, 32]), emb torch.Size([2, 768]) -> residual(11)
            Unet.forward: input.blocks(h: torch.Size([2, 384, 32, 32]), emb torch.Size([2, 768]) -> residual(12)
             Unet.forward: input.blocks(h: torch.Size([2, 384, 16, 16]), emb torch.Size([2, 768]) -> residual(13)
              Unet.forward: input.blocks(h: torch.Size([2, 768, 16, 16]), emb torch.Size([2, 768]) -> residual(14)
               Unet.forward: input.blocks(h: torch.Size([2, 768, 16, 16]), emb torch.Size([2, 768]) -> residual(15)
                Unet.forward: input.blocks(h: torch.Size([2, 768, 8, 8]), emb torch.Size([2, 768]) -> residual(16)
                 Unet.forward: input.blocks(h: torch.Size([2, 768, 8, 8]), emb torch.Size([2, 768]) -> residual(17)
                  Unet.forward: middle.blocks ->(h: torch.Size([2, 768, 8, 8]), emb torch.Size([2, 768])
                  Unet.forward: middle.blocks <-(h: torch.Size([2, 768, 8, 8]), emb torch.Size([2, 768])
                  Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 8, 8]) <- residual.pop(17) emb torch.Size([2, 768]))
                 Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 8, 8]) <- residual.pop(16) emb torch.Size([2, 768]))
                Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 8, 8]) <- residual.pop(15) emb torch.Size([2, 768]))
               Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 16, 16]) <- residual.pop(14) emb torch.Size([2, 768]))
              Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 16, 16]) <- residual.pop(13) emb torch.Size([2, 768]))
             Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 16, 16]) <- residual.pop(12) emb torch.Size([2, 768]))
            Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 32, 32]) <- residual.pop(11) emb torch.Size([2, 768]))
           Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 32, 32]) <- residual.pop(10) emb torch.Size([2, 768]))
          Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 32, 32]) <- residual.pop(9) emb torch.Size([2, 768]))
         Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 64, 64]) <- residual.pop(8) emb torch.Size([2, 768]))
        Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 64, 64]) <- residual.pop(7) emb torch.Size([2, 768]))
       Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 64, 64]) <- residual.pop(6) emb torch.Size([2, 768]))
      Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 128, 128]) <- residual.pop(5) emb torch.Size([2, 768]))
     Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 128, 128]) <- residual.pop(4) emb torch.Size([2, 768]))
    Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 128, 128]) <- residual.pop(3) emb torch.Size([2, 768]))
   Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 256, 256]) <- residual.pop(2) emb torch.Size([2, 768]))
  Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 256, 256]) <- residual.pop(1) emb torch.Size([2, 768]))
 Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 256, 256]) <- residual.pop(0) emb torch.Size([2, 768]))
 Unet.forward: out(h: torch.Size([2, 192, 256, 256]))
Unet.forward: out: torch.Size([2, 6, 256, 256]))
x = SuperResModel.forward(x): (2, 6, 256, 256)[∇:False μ:-0.14 σ:0.73 R:[-4.47:4.61]

# UNet Model output is split into 1. mean: occupying , 2.variance)
POST.GaussianDiffusion.p_mean_variance(model_output: (2, 6, 256, 256)[∇:False μ:-0.14 σ:0.73 R:[-4.47:4.61], model _WrappedModel)
:VAR.GaussianDiffusion.p_mean_variance(model_var_type: ModelVarType.LEARNED_RANGE,
	model_output (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.47:4.61]
	var (2, 3, 256, 256)[∇:False μ:0.08 σ:0.00 R:[0.08:0.08],
	logvar (2, 3, 256, 256)[∇:False μ:-2.56 σ:0.00 R:[-2.56:-2.56]
 MODELMEAN: ModelMeanType.EPSILON
  GaussianDiffusion._predict_xstart_from_eps(
  	x_t: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.48:4.61], 
	eps: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.47:4.61]
 GaussianDiffusion.q_posterior_mean_variance(
 	posterior_mean:(2, 3, 256, 256)[∇:False μ:0.00 σ:0.96 R:[-4.30:4.43],
	 posterior_variance: (2, 3, 256, 256)[∇:False μ:0.08 σ:0.00 R:[0.08:0.08],
	 posterior_log_variance_clipped: (2, 3, 256, 256)[∇:False μ:-2.56 σ:0.00 R:[-2.56:-2.56]
 MODELMEAN:ModelMeanType.EPSILON, mean: (2, 3, 256, 256)[∇:False μ:0.00 σ:0.96 R:[-4.30:4.43]
 OUT; GaussianDiffusion.p_mean_variance(mean, var, logvar, pred_xstart: (2, 3, 256, 256)[∇:False μ:-0.35 σ:0.38 R:[-1.00:1.00]
POST.GaussianDiffusion.p_sample(
	x: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.48:4.61],
	cond_fn: None, sample: (2, 3, 256, 256)[∇:False μ:0.00 σ:1.00 R:[-4.41:4.42]
	pred_xstart: (2, 3, 256, 256)[∇:False μ:-0.35 σ:0.38 R:[-1.00:1.00]

# lAST RUN
PRE.GaussianDiffusion.p_mean_variance(
	x: (2, 3, 256, 256)[∇:False μ:-0.37 σ:0.31 R:[-1.04:0.93],
	kwargs:{low_res:(2, 3, 64, 64)[∇:False μ:-0.37 σ:0.30 R:[-1.00:0.65],y:(2,)[∇:False],}
POST.GaussianDiffusion.p_mean_variance(model_output: (2, 6, 256, 256)[∇:False μ:-2.55 σ:3.23 R:[-16.45:4.21], model _WrappedModel)
:VAR.GaussianDiffusion.p_mean_variance(model_var_type: ModelVarType.LEARNED_RANGE,
	model_output (2, 3, 256, 256)[∇:False μ:-0.00 σ:0.87 R:[-4.31:4.21]
	var (2, 3, 256, 256)[∇:False μ:0.00 σ:0.00 R:[0.00:0.00],
	logvar (2, 3, 256, 256)[∇:False μ:-9.68 σ:0.21 R:[-10.56:-9.30]
 MODELMEAN: ModelMeanType.EPSILON
  GaussianDiffusion._predict_xstart_from_eps(x_t: (2, 3, 256, 256)[∇:False μ:-0.37 σ:0.31 R:[-1.04:0.93],  eps: (2, 3, 256, 256)[∇:False μ:-0.00 σ:0.87 R:[-4.31:4.21]
 MODELMEAN:ModelMeanType.EPSILON, mean: (2, 3, 256, 256)[∇:False μ:-0.37 σ:0.31 R:[-1.00:0.93]
 OUT; GaussianDiffusion.p_mean_variance(mean, var, logvar, pred_xstart: (2, 3, 256, 256)[∇:False μ:-0.37 σ:0.31 R:[-1.00:0.93]
 GaussianDiffusion.p_sample_loop( final['sample']: torch.Size([2, 3, 256, 256])
created 2 samples
saving to /tmp/openai-2022-03-16-18-03-02-123951/samples_2x256x256x3.npz
sampling complete

 ##
 # upsampling from 128-512
 #
 {'attention_resolutions': '32,16',
 'base_samples': '/home/z/work/gits/Diffusion/guided-diffusion/results/upscale64/upscale128_hare.npz',
 'batch_size': 2,
 'class_cond': True,
 'clip_denoised': True,
 'diffusion_steps': 1000,
 'dropout': 0.0,
 'large_size': 512,
 'learn_sigma': True,
 'model_path': '../models/128_512_upsampler.pt',
 'noise_schedule': 'linear',
 'num_channels': 192,
 'num_head_channels': 64,
 'num_heads': 4,
 'num_heads_upsample': -1,
 'num_res_blocks': 2,
 'num_samples': 2,
 'predict_xstart': False,
 'resblock_updown': True,
 'rescale_learned_sigmas': False,
 'rescale_timesteps': False,
 'small_size': 128,
 'timestep_respacing': '1000',
 'use_checkpoint': False,
 'use_ddim': False,
 'use_fp16': True,
 'use_kl': False,
 'use_scale_shift_norm': True}
Logging to /tmp/openai-2022-03-15-13-01-34-134770
creating model...
{'attention_resolutions': '32,16',
 'class_cond': True,
 'diffusion_steps': 1000,
 'dropout': 0.0,
 'large_size': 512,
 'learn_sigma': True,
 'noise_schedule': 'linear',
 'num_channels': 192,
 'num_head_channels': 64,
 'num_heads': 4,
 'num_heads_upsample': -1,
 'num_res_blocks': 2,
 'predict_xstart': False,
 'resblock_updown': True,
 'rescale_learned_sigmas': False,
 'rescale_timesteps': False,
 'small_size': 128,
 'timestep_respacing': '1000',
 'use_checkpoint': False,
 'use_fp16': True,
 'use_kl': False,
 'use_scale_shift_norm': True}
SuperResModel.__init__():
Unet.__init__():
	in_channels 6
	out_channels 6
	model_channels 192
	num_res_blocks 2
	attention_resolutions (16, 32)
	dropout 0.0
	conv_resample True
	num_classes 1000
	num_heads 4
	num_head_channels 64
	num_heads_upsample 4
	level[0], mult[1], res_block[0] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	level[0], mult[1], res_block[0] +TimestepEmbedSequential(*layers 1
	level[0], mult[1], res_block[1] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	level[0], mult[1], res_block[1] +TimestepEmbedSequential(*layers 1
	level[0], mult[1], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 192, time_embed_dim 768, dropout 0.0, out_channels 192, dims: 2
	 level[1], mult[1], res_block[0] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	 level[1], mult[1], res_block[0] +TimestepEmbedSequential(*layers 1
	 level[1], mult[1], res_block[1] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True
	 level[1], mult[1], res_block[1] +TimestepEmbedSequential(*layers 1
	 level[1], mult[1], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 192, time_embed_dim 768, dropout 0.0, out_channels 192, dims: 2
	  level[2], mult[2], res_block[0] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	  level[2], mult[2], res_block[0] +TimestepEmbedSequential(*layers 1
	  level[2], mult[2], res_block[1] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	  level[2], mult[2], res_block[1] +TimestepEmbedSequential(*layers 1
	  level[2], mult[2], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 384, time_embed_dim 768, dropout 0.0, out_channels 384, dims: 2
	   level[3], mult[2], res_block[0] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	   level[3], mult[2], res_block[0] +TimestepEmbedSequential(*layers 1
	   level[3], mult[2], res_block[1] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	   level[3], mult[2], res_block[1] +TimestepEmbedSequential(*layers 1
	   level[3], mult[2], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 384, time_embed_dim 768, dropout 0.0, out_channels 384, dims: 2
	    level[4], mult[4], res_block[0] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	    level[4], mult[4] ds 16 in attention_resolutions(16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:64), use_new_attention_order:False
	    level[4], mult[4], res_block[0] +TimestepEmbedSequential(*layers 2
	    level[4], mult[4], res_block[1] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	    level[4], mult[4] ds 16 in attention_resolutions(16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:64), use_new_attention_order:False
	    level[4], mult[4], res_block[1] +TimestepEmbedSequential(*layers 2
	    level[4], mult[4], res_block[1] level != len(channel_mult) - 1] +TimestepEmbedSequential(ResBlock (ch: 768, time_embed_dim 768, dropout 0.0, out_channels 768, dims: 2
	     level[5], mult[4], res_block[0] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	     level[5], mult[4] ds 32 in attention_resolutions(16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:64), use_new_attention_order:False
	     level[5], mult[4], res_block[0] +TimestepEmbedSequential(*layers 2
	     level[5], mult[4], res_block[1] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	     level[5], mult[4] ds 32 in attention_resolutions(16, 32)] +AttentionBlock(ch768, num_heads:4, num_head_channels:64), use_new_attention_order:False
	     level[5], mult[4], res_block[1] +TimestepEmbedSequential(*layers 2
	      MiddleBlock: +TimestepEmbedSequential(ResBlock (ch: 768, time_embed_dim 768, dropout 0.0, out_channels 768, dims: 2
	      AttentionBlock (ch: 768, num_heads 4, num_head_channels 64, use_new_attention_order False
	      ResBlock (ch: 768, time_embed_dim 768, dropout 0.0, out_channels 768, dims: 2
	self._feature_size += ch  8256
	     level[5], mult[4], res_block[0] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	     level[5], mult[4], AttentionBlock[0: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:64)
	     level[5], mult[4], res_block[1] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	     level[5], mult[4], AttentionBlock[1: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:64)
	     level[5], mult[4], res_block[2] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	     level[5], mult[4], AttentionBlock[2: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:64)
	     level[5], mult[4], res_block[2, level and i == num_res_blocks] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	    level[4], mult[4], res_block[0] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	    level[4], mult[4], AttentionBlock[0: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:64)
	    level[4], mult[4], res_block[1] +ResBlock(ch768 +ich768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	    level[4], mult[4], AttentionBlock[1: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:64)
	    level[4], mult[4], res_block[2] +ResBlock(ch768 +ich384, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True, UP
	    level[4], mult[4], AttentionBlock[2: ds in attention_resolutions] +AttentionBlock(ch768, num_heads:4, num_head_channels:64)
	    level[4], mult[4], res_block[2, level and i == num_res_blocks] +ResBlock(ch768, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	   level[3], mult[2], res_block[0] +ResBlock(ch768 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	   level[3], mult[2], res_block[1] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	   level[3], mult[2], res_block[2] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	   level[3], mult[2], res_block[2, level and i == num_res_blocks] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:768, dims:2, use_scale_shift_norm:True
	  level[2], mult[2], res_block[0] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	  level[2], mult[2], res_block[1] +ResBlock(ch384 +ich384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	  level[2], mult[2], res_block[2] +ResBlock(ch384 +ich192, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True, UP
	  level[2], mult[2], res_block[2, level and i == num_res_blocks] +ResBlock(ch384, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	 level[1], mult[1], res_block[0] +ResBlock(ch384 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	 level[1], mult[1], res_block[1] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	 level[1], mult[1], res_block[2] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	 level[1], mult[1], res_block[2, level and i == num_res_blocks] +ResBlock(ch192, time_embed_dim:768, dropout:0.0), out_channels:384, dims:2, use_scale_shift_norm:True
	level[0], mult[1], res_block[0] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	level[0], mult[1], res_block[1] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
	level[0], mult[1], res_block[2] +ResBlock(ch192 +ich192, time_embed_dim:768, dropout:0.0), out_channels:192, dims:2, use_scale_shift_norm:True, UP
 GaussianDiffusion.__init__()
 GaussianDiffusion.__init__()
loading data...
creating samples...
 GaussianDiffusion.p_sample_loop_progressive(indices: 1000
 1.GaussianDiffusion.p_sample(x: torch.Size([2, 3, 512, 512]), cond_fn: None, t: tensor([999, 999], device='cuda:0'), model: SuperResModel model_kwargs: {'low_res': torch.Size([2, 3, 128, 128]), 'y': torch.Size([2])}
 0.GaussianDiffusion.p_mean_variance(x: torch.Size([2, 3, 512, 512]))
SuperResModel.forward(x): torch.Size([2, 3, 512, 512]) low_res torch.Size([2, 3, 128, 128]), t: tensor([999, 999], device='cuda:0'))
/home/z/miniconda3/envs/abj/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
SuperResModel.forward; x = cat(x, upsampled): torch.Size([2, 6, 512, 512]))
Unet.forward(x: torch.Size([2, 6, 512, 512]), t: torch.Size([2]), y: torch.Size([2]))
Unet.forward(emb: torch.Size([2, 768]), timestep_embedding: torch.Size([2]), channels: 192)
Unet.forward: input.blocks(h: torch.Size([2, 6, 512, 512]), emb torch.Size([2, 768]) -> residual(0)
 Unet.forward: input.blocks(h: torch.Size([2, 192, 512, 512]), emb torch.Size([2, 768]) -> residual(1)
  Unet.forward: input.blocks(h: torch.Size([2, 192, 512, 512]), emb torch.Size([2, 768]) -> residual(2)
   Unet.forward: input.blocks(h: torch.Size([2, 192, 512, 512]), emb torch.Size([2, 768]) -> residual(3)
    Unet.forward: input.blocks(h: torch.Size([2, 192, 256, 256]), emb torch.Size([2, 768]) -> residual(4)
     Unet.forward: input.blocks(h: torch.Size([2, 192, 256, 256]), emb torch.Size([2, 768]) -> residual(5)
      Unet.forward: input.blocks(h: torch.Size([2, 192, 256, 256]), emb torch.Size([2, 768]) -> residual(6)
       Unet.forward: input.blocks(h: torch.Size([2, 192, 128, 128]), emb torch.Size([2, 768]) -> residual(7)
        Unet.forward: input.blocks(h: torch.Size([2, 384, 128, 128]), emb torch.Size([2, 768]) -> residual(8)
         Unet.forward: input.blocks(h: torch.Size([2, 384, 128, 128]), emb torch.Size([2, 768]) -> residual(9)
          Unet.forward: input.blocks(h: torch.Size([2, 384, 64, 64]), emb torch.Size([2, 768]) -> residual(10)
           Unet.forward: input.blocks(h: torch.Size([2, 384, 64, 64]), emb torch.Size([2, 768]) -> residual(11)
            Unet.forward: input.blocks(h: torch.Size([2, 384, 64, 64]), emb torch.Size([2, 768]) -> residual(12)
             Unet.forward: input.blocks(h: torch.Size([2, 384, 32, 32]), emb torch.Size([2, 768]) -> residual(13)
              Unet.forward: input.blocks(h: torch.Size([2, 768, 32, 32]), emb torch.Size([2, 768]) -> residual(14)
               Unet.forward: input.blocks(h: torch.Size([2, 768, 32, 32]), emb torch.Size([2, 768]) -> residual(15)
                Unet.forward: input.blocks(h: torch.Size([2, 768, 16, 16]), emb torch.Size([2, 768]) -> residual(16)
                 Unet.forward: input.blocks(h: torch.Size([2, 768, 16, 16]), emb torch.Size([2, 768]) -> residual(17)
                  Unet.forward: middle.blocks ->(h: torch.Size([2, 768, 16, 16]), emb torch.Size([2, 768])
                  Unet.forward: middle.blocks <-(h: torch.Size([2, 768, 16, 16]), emb torch.Size([2, 768])
                  Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 16, 16]) <- residual.pop(17) emb torch.Size([2, 768]))
                 Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 16, 16]) <- residual.pop(16) emb torch.Size([2, 768]))
                Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 16, 16]) <- residual.pop(15) emb torch.Size([2, 768]))
               Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 32, 32]) <- residual.pop(14) emb torch.Size([2, 768]))
              Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 32, 32]) <- residual.pop(13) emb torch.Size([2, 768]))
             Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 32, 32]) <- residual.pop(12) emb torch.Size([2, 768]))
            Unet.forward: output.blocks(cat(h: torch.Size([2, 768, 64, 64]) <- residual.pop(11) emb torch.Size([2, 768]))
           Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 64, 64]) <- residual.pop(10) emb torch.Size([2, 768]))
          Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 64, 64]) <- residual.pop(9) emb torch.Size([2, 768]))
         Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 128, 128]) <- residual.pop(8) emb torch.Size([2, 768]))
        Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 128, 128]) <- residual.pop(7) emb torch.Size([2, 768]))
       Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 128, 128]) <- residual.pop(6) emb torch.Size([2, 768]))
      Unet.forward: output.blocks(cat(h: torch.Size([2, 384, 256, 256]) <- residual.pop(5) emb torch.Size([2, 768]))
     Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 256, 256]) <- residual.pop(4) emb torch.Size([2, 768]))
    Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 256, 256]) <- residual.pop(3) emb torch.Size([2, 768]))
   Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 512, 512]) <- residual.pop(2) emb torch.Size([2, 768]))
  Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 512, 512]) <- residual.pop(1) emb torch.Size([2, 768]))
 Unet.forward: output.blocks(cat(h: torch.Size([2, 192, 512, 512]) <- residual.pop(0) emb torch.Size([2, 768]))
 Unet.forward: out(h: torch.Size([2, 192, 512, 512]))
Unet.forward: out: torch.Size([2, 6, 512, 512]))
x = SuperResModel.forward(x): torch.Size([2, 6, 512, 512])

 1.GaussianDiffusion.p_mean_variance(model_output: torch.Size([2, 6, 512, 512]), model _WrappedModel)
  START_X GaussianDiffusion.p_mean_variance(model_mean_type: ModelMeanType.EPSILON, x: torch.Size([2, 3, 512, 512]), eps: torch.Size([2, 3, 512, 512])
    GaussianDiffusion._predict_xstart_from_eps(x_t: torch.Size([2, 3, 512, 512]),  eps: torch.Size([2, 3, 512, 512])
      GaussianDiffusion.q_posterior_mean_variance( posterior_mean:torch.Size([2, 3, 512, 512]), posterior_variance: torch.Size([2, 3, 512, 512]), posterior_log_variance_clipped: torch.Size([2, 3, 512, 512])
  START_X GaussianDiffusion.p_mean_variance(model_mean: torch.Size([2, 3, 512, 512])
  6. GaussianDiffusion.p_mean_variance(model_mean: torch.Size([2, 3, 512, 512]), model_variance: torch.Size([2, 3, 512, 512]), model_log_variance: torch.Size([2, 3, 512, 512]), pred_xstart: torch.Size([2, 3, 512, 512])
 2.GaussianDiffusion.p_sample(x: torch.Size([2, 3, 512, 512]), cond_fn: None, sample: torch.Size([2, 3, 512, 512]) pred_xstart: torch.Size([2, 3, 512, 512])
